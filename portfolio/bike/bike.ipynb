{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import math\n",
    "    \n",
    "    from sklearn import ensemble\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    from datetime import datetime\n",
    "    \n",
    "    #Load Data with pandas, and parse the first column into datetime\n",
    "    train = pd.read_csv('train.csv', parse_dates=[0])\n",
    "    test = pd.read_csv('test.csv', parse_dates=[0])\n",
    "    \n",
    "    #Feature engineering\n",
    "       \n",
    "    temp = pd.DatetimeIndex(train['datetime'])\n",
    "    train['year'] = temp.year\n",
    "    train['month'] = temp.month\n",
    "    train['hour'] = temp.hour\n",
    "    train['weekday'] = temp.weekday\n",
    "    \n",
    "    temp = pd.DatetimeIndex(test['datetime'])\n",
    "    test['year'] = temp.year\n",
    "    test['month'] = temp.month\n",
    "    test['hour'] = temp.hour\n",
    "    test['weekday'] = temp.weekday\n",
    "                \n",
    "    #the evaluation metric is the RMSE in the log domain, \n",
    "    #so we should transform the target columns into log domain as well.\n",
    "    for col in ['casual', 'registered', 'count']:\n",
    "        train['log-' + col] = train[col].apply(lambda x: np.log1p(x))\n",
    "        \n",
    "    #Define features vector\n",
    "    features = ['season', 'holiday', 'workingday', 'weather',\n",
    "            'temp', 'atemp', 'humidity', 'windspeed', 'year',\n",
    "             'month', 'weekday', 'hour']\n",
    "    \n",
    "   \n",
    "\n",
    "    #Some of the important parameters for the GBM are:\n",
    "    #    number of trees (n_estimators)\n",
    "    #    depth of each individual tree (max_depth)\n",
    "    #    loss function (loss)\n",
    "    #    learning rate (learning_rate)   \n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators=200, max_depth=3)         \n",
    "    clf.fit(train[features], train['log-count'])\n",
    "    result = clf.predict(test[features])\n",
    "    result = np.expm1(result)\n",
    "    \n",
    "    df=pd.DataFrame({'datetime':test['datetime'], 'count':result})\n",
    "    df.to_csv('results1.csv', index = False, columns=['datetime','count'])\n",
    "    \n",
    "    #So far, not that great of a result and we are in the bottom 10%.  \n",
    "    #The first step might be to try to tune the parameters. \n",
    "    \n",
    "    #Hyperparameter tuning\n",
    "    \n",
    "    #Split data into training and validation sets\n",
    "    temp = pd.DatetimeIndex(train['datetime'])\n",
    "    training = train[temp.day <= 16]\n",
    "    validation = train[temp.day > 16]\n",
    "   \n",
    "    param_grid = {'learning_rate': [0.1, 0.05, 0.01],\n",
    "                  'max_depth': [10, 15, 20],\n",
    "                  'min_samples_leaf': [3, 5, 10, 20],\n",
    "                  }\n",
    "    \n",
    "    est = ensemble.GradientBoostingRegressor(n_estimators=500)\n",
    "    # this may take awhile \n",
    "    gs_cv = GridSearchCV(est, param_grid, n_jobs=4).fit(training[features], training['log-count'])\n",
    "    \n",
    "    # best hyperparameter setting\n",
    "    gs_cv.best_params_\n",
    "    \n",
    "    #{'learning_rate': 0.05, 'max_depth': 10, 'min_samples_leaf': 20}\n",
    "  \n",
    "  \n",
    "    error_count = mean_absolute_error(validation['log-count'], gs_cv.predict(validation[features]))\n",
    "       \n",
    "    result = gs_cv.predict(test[features])\n",
    "    result = np.expm1(result)\n",
    "    df=pd.DataFrame({'datetime':test['datetime'], 'count':result})\n",
    "    df.to_csv('results2.csv', index = False, columns=['datetime','count'])\n",
    "    # Our results are now in the top 20%!\n",
    "    \n",
    "    #Lets take a look at the number of estimators now\n",
    "    error_train=[]\n",
    "    error_validation=[]\n",
    "    for k in range(10, 501, 10):\n",
    "        clf = ensemble.GradientBoostingRegressor(\n",
    "            n_estimators=k, learning_rate = .05, max_depth = 10,\n",
    "            min_samples_leaf = 20)\n",
    "        clf.fit(training[features], training['log-count'])\n",
    "        result = clf.predict(training[features])\n",
    "        error_train.append(\n",
    "            mean_absolute_error(result, training['log-count']))\n",
    "        result = clf.predict(validation[features])\n",
    "        error_validation.append(\n",
    "            mean_absolute_error(result, validation['log-count']))        \n",
    "    \n",
    "    #Plot the data\n",
    "    x=range(10,501, 10)\n",
    "    plt.style.use('ggplot')\n",
    "    plt.plot(x, error_train, 'k')\n",
    "    plt.plot(x, error_validation, 'b')\n",
    "    plt.xlabel('Number of Estimators', fontsize=18)\n",
    "    plt.ylabel('Error', fontsize=18)\n",
    "    plt.legend(['Train', 'Validation'], fontsize=18)\n",
    "    plt.title('Error vs. Number of Estimators', fontsize=20)\n",
    "    \n",
    "    # Given that the count is the sum of registered and casual we might\n",
    "    # get better performance modeling them separately. \n",
    "    \n",
    "    def merge_predict(model1, model2, test_data):\n",
    "    #    Combine the predictions of two separately  trained models. \n",
    "    #    The input models are in the log domain and returns the predictions\n",
    "    #    in original domain.\n",
    "        p1 = np.expm1(model1.predict(test_data))\n",
    "        p2 = np.expm1(model2.predict(test_data))\n",
    "        p_total = (p1+p2)\n",
    "        return(p_total)\n",
    "        \n",
    "    est_casual = ensemble.GradientBoostingRegressor(n_estimators=80, learning_rate = .05)\n",
    "    est_registered = ensemble.GradientBoostingRegressor(n_estimators=80, learning_rate = .05)\n",
    "    param_grid2 = {'max_depth': [10, 15, 20],\n",
    "                  'min_samples_leaf': [3, 5, 10, 20],\n",
    "                  }\n",
    "                  \n",
    "    gs_casual = GridSearchCV(est_casual, param_grid2, n_jobs=4).fit(training[features], training['log-casual'])  \n",
    "    gs_registered = GridSearchCV(est_registered, param_grid2, n_jobs=4).fit(training[features], training['log-registered'])      \n",
    "    \n",
    "    error_registered = mean_absolute_error(\n",
    "        validation['log-registered'], gs_registered.predict(validation[features]))\n",
    "        \n",
    "    error_casual = mean_absolute_error(\n",
    "        validation['log-casual'], gs_casual.predict(validation[features]))\n",
    "        \n",
    "    print([error_count, error_casual, error_registered])\n",
    "    #[0.20943850897991825, 0.40021857004963229, 0.1985197355367242]\n",
    "    #If we take a look, we get the same hyper parameters which shouldn't be a big \n",
    "    #suprise            \n",
    "    \n",
    "    result3 = merge_predict(gs_casual, gs_registered, test[features])\n",
    "    df=pd.DataFrame({'datetime':test['datetime'], 'count':result3})\n",
    "    df.to_csv('results3.csv', index = False, columns=['datetime','count'])\n",
    "   \n",
    "    #Looking at the different users seperatly moved me up a few of percent,\n",
    "    #Lastly, lets train our models on the whole dateset without leaving any out for \n",
    "    #looking at our error.\n",
    "    \n",
    "    est_casual = ensemble.GradientBoostingRegressor(\n",
    "        n_estimators=80, learning_rate = .05, max_depth = 10,min_samples_leaf = 20)\n",
    "    est_registered = ensemble.GradientBoostingRegressor(\n",
    "        n_estimators=80, learning_rate = .05, max_depth = 10,min_samples_leaf = 20)\n",
    "        \n",
    "    est_casual.fit(train[features].values, train['log-casual'].values)\n",
    "    est_registered.fit(train[features].values, train['log-registered'].values)\n",
    "    result4 = merge_predict(est_casual, est_registered, test[features])\n",
    "    \n",
    "    df=pd.DataFrame({'datetime':test['datetime'], 'count':result4})\n",
    "    df.to_csv('results4.csv', index = False, columns=['datetime','count'])\n",
    "    \n",
    "    #With that I have a result in the top 10%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
