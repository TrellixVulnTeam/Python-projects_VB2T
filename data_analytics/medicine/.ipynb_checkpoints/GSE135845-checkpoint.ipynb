{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1- Pre-processing of the data, if necessary ( Normalisation, Rebalancing) Note: data has no missing values\n",
    "2-Data Visualisation (correlation evidence from visual analysis of attributes) \n",
    "3- Feature selection/extraction (PCA, LDA). Show at least two and plot the features in 2D/3D space. \n",
    "4- Classification (Use three classification algorithms and describe them in brief. Perform parameter tuning. Reasons for selecting the algorithms). \n",
    "• Performance Metrics used for Data Analysis and Knowledge Discovery. \n",
    "• What new knowledge you were able to discover from the data? How you can develop the results further? (Hint: Fuzzy Rules, Rule Extraction)\n",
    "\n",
    "\n",
    "\n",
    "I have a dataset in .txt form (GSE135845_series_matrix.txt) .It has 12 samples .\n",
    "I have converted this original txt file to CSV file \"965.csv\".\n",
    "I have divided these samples in 2 classes  i.e With madicine and Without Medicine and added a new column called \"classes\" and used 0 for \"No medicine\" class and 1 for \"Medicine class\".Also I have transposed the data\n",
    "This file is \"NNew.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, recall_score, precision_score, f1_score, confusion_matrix, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv('NNew.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 28871)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>28860</th>\n",
       "      <th>28861</th>\n",
       "      <th>28862</th>\n",
       "      <th>28863</th>\n",
       "      <th>28864</th>\n",
       "      <th>28865</th>\n",
       "      <th>28866</th>\n",
       "      <th>28867</th>\n",
       "      <th>28868</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>144.911258</td>\n",
       "      <td>27.627975</td>\n",
       "      <td>31.785642</td>\n",
       "      <td>731.149142</td>\n",
       "      <td>102.262833</td>\n",
       "      <td>1234.133142</td>\n",
       "      <td>177.216633</td>\n",
       "      <td>35.773400</td>\n",
       "      <td>2376.392975</td>\n",
       "      <td>...</td>\n",
       "      <td>961.665292</td>\n",
       "      <td>208.340483</td>\n",
       "      <td>1849.774017</td>\n",
       "      <td>127.051825</td>\n",
       "      <td>1011.955100</td>\n",
       "      <td>1127.796450</td>\n",
       "      <td>503.430167</td>\n",
       "      <td>6436.551667</td>\n",
       "      <td>271.821217</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.605551</td>\n",
       "      <td>22.175923</td>\n",
       "      <td>0.659897</td>\n",
       "      <td>1.213120</td>\n",
       "      <td>109.922630</td>\n",
       "      <td>16.563424</td>\n",
       "      <td>188.688437</td>\n",
       "      <td>56.766948</td>\n",
       "      <td>5.923796</td>\n",
       "      <td>401.854355</td>\n",
       "      <td>...</td>\n",
       "      <td>171.887109</td>\n",
       "      <td>15.348026</td>\n",
       "      <td>261.988399</td>\n",
       "      <td>11.990549</td>\n",
       "      <td>63.849382</td>\n",
       "      <td>77.766871</td>\n",
       "      <td>41.132308</td>\n",
       "      <td>540.789466</td>\n",
       "      <td>29.920924</td>\n",
       "      <td>0.452267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.133000</td>\n",
       "      <td>26.611000</td>\n",
       "      <td>30.009600</td>\n",
       "      <td>449.039000</td>\n",
       "      <td>74.626600</td>\n",
       "      <td>901.382700</td>\n",
       "      <td>119.320100</td>\n",
       "      <td>28.528000</td>\n",
       "      <td>1766.776100</td>\n",
       "      <td>...</td>\n",
       "      <td>724.887900</td>\n",
       "      <td>186.907200</td>\n",
       "      <td>1404.147200</td>\n",
       "      <td>109.792600</td>\n",
       "      <td>921.393400</td>\n",
       "      <td>1012.214000</td>\n",
       "      <td>433.786800</td>\n",
       "      <td>5680.019000</td>\n",
       "      <td>229.449400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>135.804275</td>\n",
       "      <td>27.178950</td>\n",
       "      <td>31.167775</td>\n",
       "      <td>693.538825</td>\n",
       "      <td>89.678100</td>\n",
       "      <td>1091.567450</td>\n",
       "      <td>134.446175</td>\n",
       "      <td>31.382075</td>\n",
       "      <td>2082.396475</td>\n",
       "      <td>...</td>\n",
       "      <td>837.309050</td>\n",
       "      <td>198.059725</td>\n",
       "      <td>1757.008050</td>\n",
       "      <td>119.673575</td>\n",
       "      <td>976.987300</td>\n",
       "      <td>1061.086875</td>\n",
       "      <td>469.000325</td>\n",
       "      <td>6063.161825</td>\n",
       "      <td>249.485275</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.500000</td>\n",
       "      <td>144.084650</td>\n",
       "      <td>27.594650</td>\n",
       "      <td>31.636300</td>\n",
       "      <td>734.812200</td>\n",
       "      <td>110.159650</td>\n",
       "      <td>1267.638300</td>\n",
       "      <td>155.160150</td>\n",
       "      <td>33.893150</td>\n",
       "      <td>2391.800650</td>\n",
       "      <td>...</td>\n",
       "      <td>941.945950</td>\n",
       "      <td>204.374700</td>\n",
       "      <td>1863.841350</td>\n",
       "      <td>124.092700</td>\n",
       "      <td>1010.725150</td>\n",
       "      <td>1147.882450</td>\n",
       "      <td>508.535100</td>\n",
       "      <td>6415.556850</td>\n",
       "      <td>268.132700</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.250000</td>\n",
       "      <td>157.347825</td>\n",
       "      <td>28.170275</td>\n",
       "      <td>32.102825</td>\n",
       "      <td>802.057375</td>\n",
       "      <td>114.425425</td>\n",
       "      <td>1364.509850</td>\n",
       "      <td>214.884575</td>\n",
       "      <td>39.205600</td>\n",
       "      <td>2629.775125</td>\n",
       "      <td>...</td>\n",
       "      <td>1015.057850</td>\n",
       "      <td>216.608600</td>\n",
       "      <td>1978.375700</td>\n",
       "      <td>131.894250</td>\n",
       "      <td>1049.293000</td>\n",
       "      <td>1184.771000</td>\n",
       "      <td>543.288550</td>\n",
       "      <td>6873.983525</td>\n",
       "      <td>293.756700</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>178.973600</td>\n",
       "      <td>28.676200</td>\n",
       "      <td>34.168200</td>\n",
       "      <td>868.513900</td>\n",
       "      <td>121.117500</td>\n",
       "      <td>1479.410300</td>\n",
       "      <td>302.794900</td>\n",
       "      <td>46.622000</td>\n",
       "      <td>3236.776000</td>\n",
       "      <td>...</td>\n",
       "      <td>1328.335300</td>\n",
       "      <td>236.603100</td>\n",
       "      <td>2342.477300</td>\n",
       "      <td>153.308700</td>\n",
       "      <td>1133.889600</td>\n",
       "      <td>1228.563000</td>\n",
       "      <td>555.721600</td>\n",
       "      <td>7200.712400</td>\n",
       "      <td>337.486300</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28871 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           0          1          2           3           4  \\\n",
       "count   12.000000   12.000000  12.000000  12.000000   12.000000   12.000000   \n",
       "mean     5.500000  144.911258  27.627975  31.785642  731.149142  102.262833   \n",
       "std      3.605551   22.175923   0.659897   1.213120  109.922630   16.563424   \n",
       "min      0.000000  102.133000  26.611000  30.009600  449.039000   74.626600   \n",
       "25%      2.750000  135.804275  27.178950  31.167775  693.538825   89.678100   \n",
       "50%      5.500000  144.084650  27.594650  31.636300  734.812200  110.159650   \n",
       "75%      8.250000  157.347825  28.170275  32.102825  802.057375  114.425425   \n",
       "max     11.000000  178.973600  28.676200  34.168200  868.513900  121.117500   \n",
       "\n",
       "                 5           6          7            8    ...      \\\n",
       "count    12.000000   12.000000  12.000000    12.000000    ...       \n",
       "mean   1234.133142  177.216633  35.773400  2376.392975    ...       \n",
       "std     188.688437   56.766948   5.923796   401.854355    ...       \n",
       "min     901.382700  119.320100  28.528000  1766.776100    ...       \n",
       "25%    1091.567450  134.446175  31.382075  2082.396475    ...       \n",
       "50%    1267.638300  155.160150  33.893150  2391.800650    ...       \n",
       "75%    1364.509850  214.884575  39.205600  2629.775125    ...       \n",
       "max    1479.410300  302.794900  46.622000  3236.776000    ...       \n",
       "\n",
       "             28860       28861        28862       28863        28864  \\\n",
       "count    12.000000   12.000000    12.000000   12.000000    12.000000   \n",
       "mean    961.665292  208.340483  1849.774017  127.051825  1011.955100   \n",
       "std     171.887109   15.348026   261.988399   11.990549    63.849382   \n",
       "min     724.887900  186.907200  1404.147200  109.792600   921.393400   \n",
       "25%     837.309050  198.059725  1757.008050  119.673575   976.987300   \n",
       "50%     941.945950  204.374700  1863.841350  124.092700  1010.725150   \n",
       "75%    1015.057850  216.608600  1978.375700  131.894250  1049.293000   \n",
       "max    1328.335300  236.603100  2342.477300  153.308700  1133.889600   \n",
       "\n",
       "             28865       28866        28867       28868    classes  \n",
       "count    12.000000   12.000000    12.000000   12.000000  12.000000  \n",
       "mean   1127.796450  503.430167  6436.551667  271.821217   0.750000  \n",
       "std      77.766871   41.132308   540.789466   29.920924   0.452267  \n",
       "min    1012.214000  433.786800  5680.019000  229.449400   0.000000  \n",
       "25%    1061.086875  469.000325  6063.161825  249.485275   0.750000  \n",
       "50%    1147.882450  508.535100  6415.556850  268.132700   1.000000  \n",
       "75%    1184.771000  543.288550  6873.983525  293.756700   1.000000  \n",
       "max    1228.563000  555.721600  7200.712400  337.486300   1.000000  \n",
       "\n",
       "[8 rows x 28871 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>28860</th>\n",
       "      <th>28861</th>\n",
       "      <th>28862</th>\n",
       "      <th>28863</th>\n",
       "      <th>28864</th>\n",
       "      <th>28865</th>\n",
       "      <th>28866</th>\n",
       "      <th>28867</th>\n",
       "      <th>28868</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>178.9736</td>\n",
       "      <td>28.6762</td>\n",
       "      <td>31.7815</td>\n",
       "      <td>675.6172</td>\n",
       "      <td>92.4305</td>\n",
       "      <td>1351.3121</td>\n",
       "      <td>135.6727</td>\n",
       "      <td>34.2066</td>\n",
       "      <td>2287.0100</td>\n",
       "      <td>...</td>\n",
       "      <td>1328.3353</td>\n",
       "      <td>222.3161</td>\n",
       "      <td>2342.4773</td>\n",
       "      <td>125.3880</td>\n",
       "      <td>928.8357</td>\n",
       "      <td>1183.5049</td>\n",
       "      <td>555.7216</td>\n",
       "      <td>6590.9146</td>\n",
       "      <td>263.9260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>135.9153</td>\n",
       "      <td>26.8458</td>\n",
       "      <td>31.2116</td>\n",
       "      <td>699.5127</td>\n",
       "      <td>108.4411</td>\n",
       "      <td>1063.4213</td>\n",
       "      <td>157.7874</td>\n",
       "      <td>31.1987</td>\n",
       "      <td>2003.9050</td>\n",
       "      <td>...</td>\n",
       "      <td>942.4601</td>\n",
       "      <td>186.9072</td>\n",
       "      <td>1994.8049</td>\n",
       "      <td>130.9669</td>\n",
       "      <td>992.0124</td>\n",
       "      <td>1047.5358</td>\n",
       "      <td>463.6007</td>\n",
       "      <td>6258.7314</td>\n",
       "      <td>242.1986</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>116.7858</td>\n",
       "      <td>28.1078</td>\n",
       "      <td>31.6127</td>\n",
       "      <td>830.8206</td>\n",
       "      <td>111.8782</td>\n",
       "      <td>901.3827</td>\n",
       "      <td>148.0238</td>\n",
       "      <td>33.5797</td>\n",
       "      <td>1984.0208</td>\n",
       "      <td>...</td>\n",
       "      <td>790.1002</td>\n",
       "      <td>214.7061</td>\n",
       "      <td>1825.9707</td>\n",
       "      <td>120.9621</td>\n",
       "      <td>1047.0116</td>\n",
       "      <td>1175.9851</td>\n",
       "      <td>433.7868</td>\n",
       "      <td>6572.3823</td>\n",
       "      <td>247.2808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>102.1330</td>\n",
       "      <td>27.6851</td>\n",
       "      <td>33.0668</td>\n",
       "      <td>825.4612</td>\n",
       "      <td>113.8566</td>\n",
       "      <td>1264.8517</td>\n",
       "      <td>212.0051</td>\n",
       "      <td>35.0494</td>\n",
       "      <td>2556.0955</td>\n",
       "      <td>...</td>\n",
       "      <td>724.8879</td>\n",
       "      <td>198.1736</td>\n",
       "      <td>1404.1472</td>\n",
       "      <td>109.7926</td>\n",
       "      <td>1133.8896</td>\n",
       "      <td>1023.9245</td>\n",
       "      <td>523.5878</td>\n",
       "      <td>5778.8857</td>\n",
       "      <td>293.1355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>141.7910</td>\n",
       "      <td>28.4614</td>\n",
       "      <td>31.6599</td>\n",
       "      <td>710.0635</td>\n",
       "      <td>99.2342</td>\n",
       "      <td>994.2628</td>\n",
       "      <td>152.5329</td>\n",
       "      <td>31.0850</td>\n",
       "      <td>2169.0264</td>\n",
       "      <td>...</td>\n",
       "      <td>1167.7706</td>\n",
       "      <td>200.0804</td>\n",
       "      <td>1972.8993</td>\n",
       "      <td>122.7974</td>\n",
       "      <td>1014.4892</td>\n",
       "      <td>1223.3410</td>\n",
       "      <td>547.3867</td>\n",
       "      <td>7200.7124</td>\n",
       "      <td>250.2201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28871 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0        1        2         3         4          5  \\\n",
       "0           0  178.9736  28.6762  31.7815  675.6172   92.4305  1351.3121   \n",
       "1           1  135.9153  26.8458  31.2116  699.5127  108.4411  1063.4213   \n",
       "2           2  116.7858  28.1078  31.6127  830.8206  111.8782   901.3827   \n",
       "3           3  102.1330  27.6851  33.0668  825.4612  113.8566  1264.8517   \n",
       "4           4  141.7910  28.4614  31.6599  710.0635   99.2342   994.2628   \n",
       "\n",
       "          6        7          8   ...         28860     28861      28862  \\\n",
       "0  135.6727  34.2066  2287.0100   ...     1328.3353  222.3161  2342.4773   \n",
       "1  157.7874  31.1987  2003.9050   ...      942.4601  186.9072  1994.8049   \n",
       "2  148.0238  33.5797  1984.0208   ...      790.1002  214.7061  1825.9707   \n",
       "3  212.0051  35.0494  2556.0955   ...      724.8879  198.1736  1404.1472   \n",
       "4  152.5329  31.0850  2169.0264   ...     1167.7706  200.0804  1972.8993   \n",
       "\n",
       "      28863      28864      28865     28866      28867     28868  classes  \n",
       "0  125.3880   928.8357  1183.5049  555.7216  6590.9146  263.9260        0  \n",
       "1  130.9669   992.0124  1047.5358  463.6007  6258.7314  242.1986        1  \n",
       "2  120.9621  1047.0116  1175.9851  433.7868  6572.3823  247.2808        1  \n",
       "3  109.7926  1133.8896  1023.9245  523.5878  5778.8857  293.1355        1  \n",
       "4  122.7974  1014.4892  1223.3410  547.3867  7200.7124  250.2201        0  \n",
       "\n",
       "[5 rows x 28871 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = df.isnull().T.any().T.sum()\n",
    "#drop missing data\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: %s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for %: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ffd8a3475b70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# summarize components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Explained Variance: %s\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for %: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#using PCA\n",
    "array = df.values\n",
    "X = array[:,0:28867]\n",
    "Y = array[:,28867]\n",
    "# feature extraction\n",
    "pca = PCA(n_components=5)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\") % fit.explained_variance_ratio_\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800000 of model Logistic Regression\n",
      "Accuracy: 0.800000 of model Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800000 of model Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.866667 of model Gradient Boosting\n",
      "Accuracy: 0.800000 of model KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.600000 of model Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800000 of model LDA\n",
      "Accuracy: 0.866667 of model Bagging Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800000 of model Ensemble\n"
     ]
    }
   ],
   "source": [
    "features=df.iloc[:,0:28867] #Make sure to remove Opioid.Prescriber (our target)!\n",
    "target = df['classes']\n",
    "Name=[]\n",
    "Accuracy=[]\n",
    "model1=LogisticRegression(random_state=22,C=0.000000001,solver='liblinear',max_iter=200)\n",
    "model2=GaussianNB()\n",
    "model3=RandomForestClassifier(n_estimators=200,random_state=22)\n",
    "model4=GradientBoostingClassifier(n_estimators=200)\n",
    "model5=KNeighborsClassifier()\n",
    "model6=DecisionTreeClassifier()\n",
    "model7=LinearDiscriminantAnalysis()\n",
    "model8=BaggingClassifier()\n",
    "Ensembled_model=VotingClassifier(estimators=[('lr', model1), ('gn', model2), ('rf', model3),('gb',model4),('kn',model5),('dt',model6),('lda',model7), ('bc',model8)], voting='hard')\n",
    "for model, label in zip([model1, model2, model3, model4,model5,model6,model7,model8,Ensembled_model], ['Logistic Regression','Naive Bayes','Random Forest', 'Gradient Boosting','KNN','Decision Tree','LDA', 'Bagging Classifier', 'Ensemble']):\n",
    "    scores = cross_val_score(model, features, target, cv=5, scoring='accuracy')\n",
    "    Accuracy.append(scores.mean())\n",
    "    Name.append(model.__class__.__name__)\n",
    "    print(\"Accuracy: %f of model %s\" % (scores.mean(),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
